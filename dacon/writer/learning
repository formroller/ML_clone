# =============================================================================
# (dacon) writer
# =============================================================================
1) nltk (Natural Language ToolKit)
- 자연어 처리를 위한 파이썬 패키기(아나콘다 설치시 기본적으로 설치.)
- nltk 기능을 제대로 사용하기 위해서는 nltk data라는 여러 데이터를 추가적으로 설치해야한다.
(기능)
 1) 말뭉치
 2) 토큰 생성
 3) 형태소 분석
 4) 품사 태깅

2)
말뭉치 : 자연어 분석 작업을 위해 만든 샘플 문서 집합.
        품사, 형태소 등의 보조적인 의미를 추가하고 쉬운 분석읠 위해 구조적 형태로 정리한 것.

토큰 : 문자열 단위 
      자연어 문서 분석하기 위해 긴 문자열을 분석 위한 작은 단위로 나누어야 하고 이 문자열 단위를 토큰이라 한다.
      이렇게 문자열을 토큰으로 나누는 작업을 토큰 생성(Tokenizing)이라 한다.

형태소 분석: 일정한 의미가 있는 가장 작은 말의 단위
            보통 자연어 처리에서는 토큰으로 형태소를 이용한다.
            - 어간 추출(stemming)
            - 원형 복원(lemmatizing)
            - 품사 부착(Part-of-Speech tagging)

품사 부착 : 낱말을 문법적인 기능이나 형태, 뜻에 따라 구분한것.            


3) word_tokenize
space단위와 구두점(punctuation)을 기준으로 토큰화(Tokenize)한다.

4) log_loss
from sklearn.metrics import log_loss

최적화된 coefficients(계수)와 intercept(절편)를 구하기 위해,
주어진 모델이 데이터에 얼마나 fit한지 측정하는 기준이 필요하며, 이를 ML에서는 lost function 혹은 cost function 이라한다.

모델이 데이터에 'fit'한걸 측정하기 위새 먼저 각 데이터에 대한 loss를 계산 한 뒤 loss의 평균을 내야한다.
Logistic Regression에서의 loss function은 Log Loss라 하며, 공식은 참고 사이트에 있다.

m : 전체 데이터 개수
y^(i) : i번째 데이터의 class
a^(i) : i번쩨 데이터의 log-odds 값에 sigmoid를 취한값.
        즉, i번째 데이터가 positive class에 속할 확률을 나타낸 값. (0 <= a^(i) <= 1)

5) Pipeline
from sklearn.pipeline import Pipeline

- 할 일의 순서를 하나씩 넣어주는 객체를 사용한다.(개념)

# =============================================================================
# 참고
# =============================================================================
1) nltk, https://wikidocs.net/22488
2) nltk, https://datascienceschool.net/03%20machine%20learning/03.01.01%20NLTK%20%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%20%ED%8C%A8%ED%82%A4%EC%A7%80.html
3) word_tokenize, https://excelsior-cjh.tistory.com/63
4) log_loss, https://eunsukimme.github.io/ml/2019/10/22/Logistic-Regression/
5) Pipeline, https://blog.naver.com/gdpresent/221730873049
             https://pinkwink.kr/1278
